{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efaede7",
   "metadata": {},
   "source": [
    "### Splitting data by asking questions\n",
    "#### Applications: Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179efa6",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"DecisionTree1\" src=\"images/DT1.png\" width=\"400\" height=\"400\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Good Decision Tree</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"DecisionTree2\" src=\"images/DT2.png\" width=\"450\" height=\"450\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Bad Decision Tree</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4048a372",
   "metadata": {},
   "source": [
    "1. We need to pick a good first question for the root of our tree out of 5 given candidates\n",
    "    1. Is it raining?\n",
    "    2. Is it cold outside (temperature check)?\n",
    "    3. Am I hungry?\n",
    "    4. Is there a red car outside?\n",
    "    5. Is it Monday?\n",
    "2. Pick a question resulting good accuracy or gini index or entropy\n",
    "3. $\\color{red}{\\text{It is a process of always picking the best possible question (greedy algorithm). But this does not guarantee that we get best possible tree.}}$ <br>\n",
    "Note: This is a quick process (each node requires linear search) and workd very well most of the time. In future try to remove this greedy property\n",
    "4. $\\color{red}{\\text{Build all possible decision trees and pick the best one from there}}$ <br>\n",
    "Note: If dataset has many features then number of possible decision trees is very large. Going through all of them would be very slow\n",
    "5. In classification leaves have classes, and in regression the leaves have values. Prediction of our model is given by traversing the tree downwad fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c6316",
   "metadata": {},
   "source": [
    "### Understand the algorithm by solving the following problem\n",
    "#### Decision Tree as Classifier:\n",
    "#### Problem: Recommend apps to users according to what they are likely to download\n",
    "\n",
    "**Apps to be recommended (Target):**\n",
    "1. Atom Count - An app that counts number of atoms in your body\n",
    "2. Beehive Finder - An app that maps your location and finds the closest beehives\n",
    "3. Check Mate Mate - An app for finding Australian chess players <br>\n",
    "\n",
    "<img alt=\"DecisionTree3\" src=\"images/DT3.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "**Dataset:** <br>\n",
    "\n",
    "| Platform | Age | App |\n",
    "| :- | -: | :-: |\n",
    "| iPhone | 15 | Atom Count\n",
    "| iPhone | 25 | Check Mate Mate\n",
    "| Android | 32 | Beehive Finder\n",
    "| iPhone | 35 | Check Mate Mate\n",
    "| Android | 12 | Atom Count\n",
    "| Android | 14 | Atom Count\n",
    "\n",
    "Which app would you recommend to each of the following three customers? <br>\n",
    "• Customer 1: a 13-year-old iPhone user <br>\n",
    "• Customer 2: a 28-year-old iPhone user <br>\n",
    "• Customer 3: a 34-year-old Android user <br>\n",
    "\n",
    "**_Human Solution:_**<br>\n",
    "Customer 1: a 13-year-old iPhone user. To this customer, we should recommend Atom Count,\n",
    "because it seems (looking at the three customers in their teens) that young people tend to download\n",
    "Atom Count. <br>\n",
    "Customer 2: a 28-year-old iPhone user. To this customer, we should recommend Check Mate\n",
    "Mate, because looking at the two iPhone users in the dataset (aged 25 and 35), they both downloaded\n",
    "Check Mate Mate. <br>\n",
    "Customer 3: a 34-year-old Android user. To this customer, we should recommend Beehive Finder,\n",
    "because there is one Android user in the dataset who is 32 years old, and they downloaded Beehive\n",
    "Finder. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19a0da",
   "metadata": {},
   "source": [
    "#### Solution: Building an app-recommendation algorithm\n",
    "\n",
    "1. Simplify the problem by converting numerical feature age to categorical feature <br>\n",
    "\n",
    "| Platform | Age | App |\n",
    "| :- | -: | :-: |\n",
    "| iPhone | Young | Atom Count\n",
    "| iPhone | Adult | Check Mate Mate\n",
    "| Android | Adult | Beehive Finder\n",
    "| iPhone | Adult | Check Mate Mate\n",
    "| Android | Young | Atom Count\n",
    "| Android | Young | Atom Count\n",
    "\n",
    "2. Classifer1: Question: Does the user use an iPhone or Android? (splits into two groups iPhones and Androids) - App with majority is recommendable output\n",
    "\n",
    "3. Classifier2: Question: Is the user young or adult? (splits into two groups Youngs and Adults) - App with majority is recommendable output\n",
    "\n",
    "4. Calculate **accuracy** for all classifiers (higher the accuracy better the classifer)\n",
    "<img alt=\"DecisionTree4\" src=\"images/DT4.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "5. Calculate **Gini impurity index** - measure of diversity (Lower the gini index better the classifer - lower gini represents elements are similar, large gini represents elements are different) <br>\n",
    "$\\;Gini\\_impurity\\_index = P(picking\\_two\\_elements\\_different) \\\\\n",
    "\\hspace{4cm}           = 1 - P(picking\\_two\\_elements\\_similar) \\\\\n",
    "\\hspace{4cm}           = 1 - p_{1}^{2} - p_{2}^{2} - p_{3}^{2} \\;=>[since\\;three\\;apps\\;exists\\;in\\;dataset]$\n",
    "    Classifier1 (by platform):\n",
    "        - Left Leaf (iPhone):{A,C,C}\n",
    "        - Right leaf (Android):{A,A,B}\n",
    "    Classifier2 (by age):\n",
    "        - Left leaf (young):{A,A,A}\n",
    "        - Right leaf (adult):{B,C,C}\n",
    "    The gini indices of sets {A,C,C},{A,A,B}, and {B,C,C} are all the same: $1-(\\frac{2}{3})^{2}-(\\frac{1}{3})^{2}-0=0.444$ <br>\n",
    "    The gini index of set {A,A,A} is $1-(\\frac{3}{3})^{2}-0-0=0$ (gini index of pure set is always 0) <br>\n",
    "    Classifier1: Average gini index = $\\frac{0.444+0.444}{2} = 0.444$ <br>\n",
    "    Classifier2: Average gini index = $\\frac{0.444+0}{2} = 0.222$\n",
    "<img alt=\"DecisionTree5\" src=\"images/DT5.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "*NOTE: The Gini impurity index should not be confused with the Gini coefficient. The Gini coefficient is used in statistics to calculate the income or wealth inequality in countries. In this book, whenever we talk about the Gini index, we are referring to the Gini impurity index.* <br>\n",
    "\n",
    "6. Calculate **Entropy** - measure of diversity (measure of homogeneity) <br>\n",
    "$\\;Entropy = -p_{1}log_{2}(p_{1})-p_{2}log_{2}(p_{2})...-p_{n}log_{2}(p_{n}) $ <br> \n",
    "    Classifier1 (by platform):\n",
    "        - Left Leaf (iPhone):{A,C,C}\n",
    "        - Right leaf (Android):{A,A,B}\n",
    "    Classifier2 (by age):\n",
    "        - Left leaf (young):{A,A,A}\n",
    "        - Right leaf (adult):{B,C,C}\n",
    "    The entropies of sets {A,C,C},{A,A,B}, and {B,C,C} are all the same: $-\\frac{2}{3}log_{2}(\\frac{2}{3})-\\frac{1}{3}log_{2}(\\frac{1}{3})-0=0.918$ <br>\n",
    "    The entropy of set {A,A,A} is $-\\frac{3}{3}log_{2}(\\frac{3}{3})-0-0=log_{2}(1)=0$ (gini index of pure set is always 0) <br>\n",
    "    Classifier1: Average entropy = $\\frac{0.918+0.918}{2} = 0.918$ <br>\n",
    "    Classifier2: Average entropy = $\\frac{0.918+0}{2} = 0.459$\n",
    "<img alt=\"DecisionTree6\" src=\"images/DT6.png\" width=\"600\" align=\"center\"/>\n",
    "    Thus, again we conclude that the second split is better, because it has a lower average entropy.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ed4d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c67b3e",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"left\" style=\"padding: 10px\">\n",
    "    <img alt=\"DecisionTree1\" src=\"images/DT1.png\" width=\"400\" height=\"400\" align='left>\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Good Decision Tree</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
